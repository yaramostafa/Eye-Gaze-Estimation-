{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "isCoaPsw13PL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VNPmN0u_2CQh"
   },
   "outputs": [],
   "source": [
    "input_path = \"C:/Users/AS-GP/Desktop/Resnet50/lisat_gaze_data_v1/lisat_gaze_data_mixed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: C:/Users/AS-GP/Desktop/Resnet50/lisat_gaze_data_v1/lisat_gaze_data_mixed/\n",
      "Number of files: 2\n",
      "--------------------\n",
      "Folder: C:/Users/AS-GP/Desktop/Resnet50/lisat_gaze_data_v1/lisat_gaze_data_mixed/train\n",
      "Number of files: 0\n",
      "--------------------\n",
      "Folder: C:/Users/AS-GP/Desktop/Resnet50/lisat_gaze_data_v1/lisat_gaze_data_mixed/train\\Eyes Closed\n",
      "Number of files: 2969\n",
      "--------------------\n",
      "Folder: C:/Users/AS-GP/Desktop/Resnet50/lisat_gaze_data_v1/lisat_gaze_data_mixed/train\\Forward\n",
      "Number of files: 3537\n",
      "--------------------\n",
      "Folder: C:/Users/AS-GP/Desktop/Resnet50/lisat_gaze_data_v1/lisat_gaze_data_mixed/train\\Left Mirror\n",
      "Number of files: 3251\n",
      "--------------------\n",
      "Folder: C:/Users/AS-GP/Desktop/Resnet50/lisat_gaze_data_v1/lisat_gaze_data_mixed/train\\Radio\n",
      "Number of files: 3537\n",
      "--------------------\n",
      "Folder: C:/Users/AS-GP/Desktop/Resnet50/lisat_gaze_data_v1/lisat_gaze_data_mixed/train\\Rearview\n",
      "Number of files: 3433\n",
      "--------------------\n",
      "Folder: C:/Users/AS-GP/Desktop/Resnet50/lisat_gaze_data_v1/lisat_gaze_data_mixed/train\\Right Mirror\n",
      "Number of files: 3140\n",
      "--------------------\n",
      "Folder: C:/Users/AS-GP/Desktop/Resnet50/lisat_gaze_data_v1/lisat_gaze_data_mixed/train\\Shoulder\n",
      "Number of files: 6345\n",
      "--------------------\n",
      "Folder: C:/Users/AS-GP/Desktop/Resnet50/lisat_gaze_data_v1/lisat_gaze_data_mixed/train\\Speedometer\n",
      "Number of files: 3793\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def count_files_in_folders(directory):\n",
    "  for root, dirs, files in os.walk(directory):\n",
    "    print(f\"Folder: {root}\")\n",
    "    file_count = len(files)\n",
    "    print(f\"Number of files: {file_count}\")\n",
    "    print(\"-\" * 20) # Replace 'path_to_your_directory' with the directory path you want to inspectdirectory_path = 'path_to_your_directory'\n",
    "count_files_in_folders(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24004\n",
      "6001\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "}\n",
    "full_dataset = datasets.ImageFolder(input_path + \n",
    "                                    '/train', \n",
    "                                    data_transforms['train'])\n",
    "\n",
    "# Calculate the sizes of the training and validation sets\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders for training and validation sets\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(train_dataset,\n",
    "                                         batch_size=32,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=2),\n",
    "    'validation': torch.utils.data.DataLoader(val_dataset,\n",
    "                                              batch_size=32,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=2)\n",
    "}\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6k7yDdFAATD5",
    "outputId": "1fd34c8f-e637-4c9e-ab5f-0d6c9712fa00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sq056PqWBILr",
    "outputId": "7644d8c5-777d-482a-b71c-8c8aa4d7a55b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AS-GP\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\AS-GP\\AppData\\Local\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =torchvision.models.mobilenet_v2(pretrained=True).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8_l7PyhiCJq3",
    "outputId": "fb97bfc9-8e6d-4b9e-f2d3-915aba69ef54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=8, bias=True)\n",
       "    (2): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 =torchvision.models.mobilenet_v2(pretrained=True).to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model2.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=1280, out_features=8, bias=True),\n",
    "            nn.Softmax(dim=1))\n",
    "\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "bdresbWBCjr9"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model2.classifier.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=10, min_delta=0.5):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_accuracy = 0\n",
    "\n",
    "    def early_stop(self, current_accuracy):\n",
    "        if (current_accuracy > self.best_accuracy + self.min_delta):\n",
    "            self.best_accuracy = current_accuracy\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path='MNV2_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "AvRU7t-RCpbr"
   },
   "outputs": [],
   "source": [
    "early_stopper = EarlyStopper(10,0.01)\n",
    "def train_model(model2, criterion, optimizer, num_epochs=5):\n",
    "    training_accuracies = []\n",
    "    validation_accuracies = []\n",
    "    training_accuracies.append(0)\n",
    "    validation_accuracies.append(0)\n",
    "    #optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model2.train().to(device) #added to device\n",
    "            else:\n",
    "                model2.eval().to(device)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model2(inputs).to(device)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                epoch_loss = running_loss / len(train_dataset)\n",
    "                epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "                training_accuracies.append(epoch_acc.item()*100)\n",
    "            else:\n",
    "                epoch_loss = running_loss / len(val_dataset)\n",
    "                epoch_acc = running_corrects.double() / len(val_dataset)\n",
    "                validation_accuracies.append(epoch_acc.item()*100)\n",
    "                if early_stopper.early_stop(epoch_acc.item()*100):\n",
    "                    print('triggered ES Tacc: {:.4f}, Vacc: {:.4f}'.format(training_accuracies[-1], \n",
    "                                                                           validation_accuracies[-1]))            \n",
    "                    return model,training_accuracies,validation_accuracies\n",
    "            \n",
    "                if epoch_acc.item()*100 >= early_stopper.best_accuracy:\n",
    "                    #early_stopper.early_stop(epoch_acc.item()*100)\n",
    "                    #early_stopper.best_accuracy = epoch_acc.item()*100\n",
    "                    print('best accuracy {:.4f}'.format(early_stopper.best_accuracy))\n",
    "                    torch.save(model.state_dict(), weights_path)\n",
    "                    print(f\"Model saved as it achieved the best validation accuracy so far {early_stopper.best_accuracy}\" )\n",
    "\n",
    "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
    "                                                        epoch_loss,\n",
    "                                                        epoch_acc))\n",
    "    return model2,training_accuracies,validation_accuracies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "iL_8tkqkC3ha",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train loss: 1.8370, acc: 0.5147\n",
      "best accuracy 58.0070\n",
      "Model saved as it achieved the best validation accuracy so far 58.006998833527746\n",
      "validation loss: 1.7832, acc: 0.5801\n",
      "Epoch 2/100\n",
      "----------\n",
      "train loss: 1.7856, acc: 0.5641\n",
      "best accuracy 59.4734\n",
      "Model saved as it achieved the best validation accuracy so far 59.473421096483925\n",
      "validation loss: 1.7477, acc: 0.5947\n",
      "Epoch 3/100\n",
      "----------\n",
      "train loss: 1.7556, acc: 0.5857\n",
      "best accuracy 62.2063\n",
      "Model saved as it achieved the best validation accuracy so far 62.206298950174975\n",
      "validation loss: 1.7236, acc: 0.6221\n",
      "Epoch 4/100\n",
      "----------\n",
      "train loss: 1.7355, acc: 0.5985\n",
      "best accuracy 63.0728\n",
      "Model saved as it achieved the best validation accuracy so far 63.07282119646725\n",
      "validation loss: 1.7066, acc: 0.6307\n",
      "Epoch 5/100\n",
      "----------\n",
      "train loss: 1.7221, acc: 0.6089\n",
      "best accuracy 63.5227\n",
      "Model saved as it achieved the best validation accuracy so far 63.522746208965174\n",
      "validation loss: 1.6896, acc: 0.6352\n",
      "Epoch 6/100\n",
      "----------\n",
      "train loss: 1.7135, acc: 0.6106\n",
      "best accuracy 63.9893\n",
      "Model saved as it achieved the best validation accuracy so far 63.98933511081487\n",
      "validation loss: 1.6837, acc: 0.6399\n",
      "Epoch 7/100\n",
      "----------\n",
      "train loss: 1.7055, acc: 0.6148\n",
      "best accuracy 64.5392\n",
      "Model saved as it achieved the best validation accuracy so far 64.53924345942343\n",
      "validation loss: 1.6763, acc: 0.6454\n",
      "Epoch 8/100\n",
      "----------\n",
      "train loss: 1.6970, acc: 0.6209\n",
      "best accuracy 64.5892\n",
      "Model saved as it achieved the best validation accuracy so far 64.58923512747876\n",
      "validation loss: 1.6703, acc: 0.6459\n",
      "Epoch 9/100\n",
      "----------\n",
      "train loss: 1.6923, acc: 0.6197\n",
      "best accuracy 65.2225\n",
      "Model saved as it achieved the best validation accuracy so far 65.2224629228462\n",
      "validation loss: 1.6654, acc: 0.6522\n",
      "Epoch 10/100\n",
      "----------\n",
      "train loss: 1.6803, acc: 0.6361\n",
      "best accuracy 67.5721\n",
      "Model saved as it achieved the best validation accuracy so far 67.57207132144643\n",
      "validation loss: 1.6435, acc: 0.6757\n",
      "Epoch 11/100\n",
      "----------\n",
      "train loss: 1.6664, acc: 0.6532\n",
      "best accuracy 69.7717\n",
      "Model saved as it achieved the best validation accuracy so far 69.77170471588069\n",
      "validation loss: 1.6269, acc: 0.6977\n",
      "Epoch 12/100\n",
      "----------\n",
      "train loss: 1.6569, acc: 0.6621\n",
      "validation loss: 1.6295, acc: 0.6934\n",
      "Epoch 13/100\n",
      "----------\n",
      "train loss: 1.6525, acc: 0.6642\n",
      "validation loss: 1.6231, acc: 0.6957\n",
      "Epoch 14/100\n",
      "----------\n",
      "train loss: 1.6481, acc: 0.6647\n",
      "best accuracy 70.6382\n",
      "Model saved as it achieved the best validation accuracy so far 70.63822696217298\n",
      "validation loss: 1.6106, acc: 0.7064\n",
      "Epoch 15/100\n",
      "----------\n",
      "train loss: 1.6408, acc: 0.6738\n",
      "best accuracy 71.4048\n",
      "Model saved as it achieved the best validation accuracy so far 71.40476587235462\n",
      "validation loss: 1.6008, acc: 0.7140\n",
      "Epoch 16/100\n",
      "----------\n",
      "train loss: 1.6336, acc: 0.6797\n",
      "validation loss: 1.6015, acc: 0.7135\n",
      "Epoch 17/100\n",
      "----------\n",
      "train loss: 1.6282, acc: 0.6835\n",
      "best accuracy 71.8880\n",
      "Model saved as it achieved the best validation accuracy so far 71.88801866355607\n",
      "validation loss: 1.5958, acc: 0.7189\n",
      "Epoch 18/100\n",
      "----------\n",
      "train loss: 1.6255, acc: 0.6866\n",
      "best accuracy 72.8545\n",
      "Model saved as it achieved the best validation accuracy so far 72.85452424595901\n",
      "validation loss: 1.5852, acc: 0.7285\n",
      "Epoch 19/100\n",
      "----------\n",
      "train loss: 1.6234, acc: 0.6871\n",
      "validation loss: 1.5880, acc: 0.7225\n",
      "Epoch 20/100\n",
      "----------\n",
      "train loss: 1.6209, acc: 0.6873\n",
      "validation loss: 1.5868, acc: 0.7260\n",
      "Epoch 21/100\n",
      "----------\n",
      "train loss: 1.6167, acc: 0.6929\n",
      "validation loss: 1.5809, acc: 0.7277\n",
      "Epoch 22/100\n",
      "----------\n",
      "train loss: 1.6160, acc: 0.6899\n",
      "validation loss: 1.5844, acc: 0.7194\n",
      "Epoch 23/100\n",
      "----------\n",
      "train loss: 1.6149, acc: 0.6910\n",
      "best accuracy 73.0212\n",
      "Model saved as it achieved the best validation accuracy so far 73.02116313947677\n",
      "validation loss: 1.5795, acc: 0.7302\n",
      "Epoch 24/100\n",
      "----------\n",
      "train loss: 1.6109, acc: 0.6950\n",
      "best accuracy 73.5044\n",
      "Model saved as it achieved the best validation accuracy so far 73.50441593067822\n",
      "validation loss: 1.5738, acc: 0.7350\n",
      "Epoch 25/100\n",
      "----------\n",
      "train loss: 1.6049, acc: 0.7004\n",
      "best accuracy 74.2710\n",
      "Model saved as it achieved the best validation accuracy so far 74.27095484085986\n",
      "validation loss: 1.5643, acc: 0.7427\n",
      "Epoch 26/100\n",
      "----------\n",
      "train loss: 1.6036, acc: 0.7017\n",
      "best accuracy 74.2710\n",
      "Model saved as it achieved the best validation accuracy so far 74.27095484085986\n",
      "validation loss: 1.5674, acc: 0.7427\n",
      "Epoch 27/100\n",
      "----------\n",
      "train loss: 1.6004, acc: 0.7052\n",
      "best accuracy 74.6542\n",
      "Model saved as it achieved the best validation accuracy so far 74.65422429595068\n",
      "validation loss: 1.5607, acc: 0.7465\n",
      "Epoch 28/100\n",
      "----------\n",
      "train loss: 1.5994, acc: 0.7071\n",
      "validation loss: 1.5699, acc: 0.7374\n",
      "Epoch 29/100\n",
      "----------\n",
      "train loss: 1.5983, acc: 0.7078\n",
      "best accuracy 75.0208\n",
      "Model saved as it achieved the best validation accuracy so far 75.02082986168972\n",
      "validation loss: 1.5582, acc: 0.7502\n",
      "Epoch 30/100\n",
      "----------\n",
      "train loss: 1.5932, acc: 0.7116\n",
      "best accuracy 75.1708\n",
      "Model saved as it achieved the best validation accuracy so far 75.1708048658557\n",
      "validation loss: 1.5539, acc: 0.7517\n",
      "Epoch 31/100\n",
      "----------\n",
      "train loss: 1.5920, acc: 0.7115\n",
      "validation loss: 1.5579, acc: 0.7474\n",
      "Epoch 32/100\n",
      "----------\n",
      "train loss: 1.5927, acc: 0.7126\n",
      "validation loss: 1.5612, acc: 0.7417\n",
      "Epoch 33/100\n",
      "----------\n",
      "train loss: 1.5901, acc: 0.7144\n",
      "best accuracy 75.9540\n",
      "Model saved as it achieved the best validation accuracy so far 75.95400766538911\n",
      "validation loss: 1.5506, acc: 0.7595\n",
      "Epoch 34/100\n",
      "----------\n",
      "train loss: 1.5878, acc: 0.7165\n",
      "validation loss: 1.5483, acc: 0.7549\n",
      "Epoch 35/100\n",
      "----------\n",
      "train loss: 1.5861, acc: 0.7173\n",
      "validation loss: 1.5491, acc: 0.7545\n",
      "Epoch 36/100\n",
      "----------\n",
      "train loss: 1.5881, acc: 0.7151\n",
      "validation loss: 1.5495, acc: 0.7567\n",
      "Epoch 37/100\n",
      "----------\n",
      "train loss: 1.5851, acc: 0.7172\n",
      "validation loss: 1.5475, acc: 0.7567\n",
      "Epoch 38/100\n",
      "----------\n",
      "train loss: 1.5840, acc: 0.7178\n",
      "best accuracy 75.9540\n",
      "Model saved as it achieved the best validation accuracy so far 75.95400766538911\n",
      "validation loss: 1.5444, acc: 0.7595\n",
      "Epoch 39/100\n",
      "----------\n",
      "train loss: 1.5848, acc: 0.7159\n",
      "best accuracy 76.0540\n",
      "Model saved as it achieved the best validation accuracy so far 76.05399100149975\n",
      "validation loss: 1.5435, acc: 0.7605\n",
      "Epoch 40/100\n",
      "----------\n",
      "train loss: 1.5824, acc: 0.7190\n",
      "best accuracy 76.3373\n",
      "Model saved as it achieved the best validation accuracy so far 76.33727712047992\n",
      "validation loss: 1.5405, acc: 0.7634\n",
      "Epoch 41/100\n",
      "----------\n",
      "train loss: 1.5837, acc: 0.7150\n",
      "validation loss: 1.5423, acc: 0.7612\n",
      "Epoch 42/100\n",
      "----------\n",
      "train loss: 1.5820, acc: 0.7177\n",
      "best accuracy 76.4539\n",
      "Model saved as it achieved the best validation accuracy so far 76.45392434594235\n",
      "validation loss: 1.5381, acc: 0.7645\n",
      "Epoch 43/100\n",
      "----------\n",
      "train loss: 1.5773, acc: 0.7218\n",
      "validation loss: 1.5400, acc: 0.7577\n",
      "Epoch 44/100\n",
      "----------\n",
      "train loss: 1.5757, acc: 0.7235\n",
      "validation loss: 1.5445, acc: 0.7577\n",
      "Epoch 45/100\n",
      "----------\n",
      "train loss: 1.5776, acc: 0.7207\n",
      "validation loss: 1.5422, acc: 0.7554\n",
      "Epoch 46/100\n",
      "----------\n",
      "train loss: 1.5774, acc: 0.7224\n",
      "validation loss: 1.5400, acc: 0.7615\n",
      "Epoch 47/100\n",
      "----------\n",
      "train loss: 1.5736, acc: 0.7230\n",
      "validation loss: 1.5341, acc: 0.7624\n",
      "Epoch 48/100\n",
      "----------\n",
      "train loss: 1.5710, acc: 0.7278\n",
      "best accuracy 76.5206\n",
      "Model saved as it achieved the best validation accuracy so far 76.52057990334946\n",
      "validation loss: 1.5332, acc: 0.7652\n",
      "Epoch 49/100\n",
      "----------\n",
      "train loss: 1.5730, acc: 0.7248\n",
      "validation loss: 1.5451, acc: 0.7524\n",
      "Epoch 50/100\n",
      "----------\n",
      "train loss: 1.5733, acc: 0.7238\n",
      "validation loss: 1.5419, acc: 0.7560\n",
      "Epoch 51/100\n",
      "----------\n",
      "train loss: 1.5743, acc: 0.7204\n",
      "validation loss: 1.5356, acc: 0.7625\n",
      "Epoch 52/100\n",
      "----------\n",
      "train loss: 1.5704, acc: 0.7266\n",
      "best accuracy 77.1538\n",
      "Model saved as it achieved the best validation accuracy so far 77.15380769871689\n",
      "validation loss: 1.5274, acc: 0.7715\n",
      "Epoch 53/100\n",
      "----------\n",
      "train loss: 1.5723, acc: 0.7245\n",
      "validation loss: 1.5350, acc: 0.7674\n",
      "Epoch 54/100\n",
      "----------\n",
      "train loss: 1.5731, acc: 0.7224\n",
      "validation loss: 1.5313, acc: 0.7669\n",
      "Epoch 55/100\n",
      "----------\n",
      "train loss: 1.5705, acc: 0.7232\n",
      "validation loss: 1.5318, acc: 0.7687\n",
      "Epoch 56/100\n",
      "----------\n",
      "train loss: 1.5717, acc: 0.7260\n",
      "validation loss: 1.5348, acc: 0.7622\n",
      "Epoch 57/100\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.5676, acc: 0.7275\n",
      "validation loss: 1.5300, acc: 0.7664\n",
      "Epoch 58/100\n",
      "----------\n",
      "train loss: 1.5692, acc: 0.7250\n",
      "best accuracy 77.5704\n",
      "Model saved as it achieved the best validation accuracy so far 77.57040493251125\n",
      "validation loss: 1.5229, acc: 0.7757\n",
      "Epoch 59/100\n",
      "----------\n",
      "train loss: 1.5676, acc: 0.7264\n",
      "validation loss: 1.5311, acc: 0.7674\n",
      "Epoch 60/100\n",
      "----------\n",
      "train loss: 1.5678, acc: 0.7259\n",
      "validation loss: 1.5246, acc: 0.7709\n",
      "Epoch 61/100\n",
      "----------\n",
      "train loss: 1.5690, acc: 0.7245\n",
      "validation loss: 1.5283, acc: 0.7650\n",
      "Epoch 62/100\n",
      "----------\n",
      "train loss: 1.5670, acc: 0.7255\n",
      "validation loss: 1.5246, acc: 0.7727\n",
      "Epoch 63/100\n",
      "----------\n",
      "train loss: 1.5673, acc: 0.7257\n",
      "best accuracy 77.9370\n",
      "Model saved as it achieved the best validation accuracy so far 77.93701049825029\n",
      "validation loss: 1.5215, acc: 0.7794\n",
      "Epoch 64/100\n",
      "----------\n",
      "train loss: 1.5670, acc: 0.7266\n",
      "validation loss: 1.5225, acc: 0.7769\n",
      "Epoch 65/100\n",
      "----------\n",
      "train loss: 1.5675, acc: 0.7261\n",
      "validation loss: 1.5244, acc: 0.7697\n",
      "Epoch 66/100\n",
      "----------\n",
      "train loss: 1.5674, acc: 0.7235\n",
      "validation loss: 1.5223, acc: 0.7742\n",
      "Epoch 67/100\n",
      "----------\n",
      "train loss: 1.5629, acc: 0.7292\n",
      "validation loss: 1.5194, acc: 0.7779\n",
      "Epoch 68/100\n",
      "----------\n",
      "train loss: 1.5677, acc: 0.7240\n",
      "validation loss: 1.5253, acc: 0.7699\n",
      "Epoch 69/100\n",
      "----------\n",
      "train loss: 1.5629, acc: 0.7293\n",
      "validation loss: 1.5184, acc: 0.7747\n",
      "Epoch 70/100\n",
      "----------\n",
      "train loss: 1.5619, acc: 0.7340\n",
      "validation loss: 1.5259, acc: 0.7680\n",
      "Epoch 71/100\n",
      "----------\n",
      "train loss: 1.5598, acc: 0.7331\n",
      "validation loss: 1.5204, acc: 0.7739\n",
      "Epoch 72/100\n",
      "----------\n",
      "train loss: 1.5607, acc: 0.7318\n",
      "validation loss: 1.5260, acc: 0.7680\n",
      "Epoch 73/100\n",
      "----------\n",
      "train loss: 1.5599, acc: 0.7340\n",
      "triggered ES Tacc: 73.3961, Vacc: 77.5037\n"
     ]
    }
   ],
   "source": [
    "model_trained = train_model(model2, criterion, optimizer, num_epochs=100) #1 epoch for testing gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Ev6eNi1rC4L0"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m weights_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/AS-GP/Desktop/MobileNet/MNV2_weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# model weights\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model_trained\u001b[38;5;241m.\u001b[39mstate_dict(), weights_path)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'state_dict'"
     ]
    }
   ],
   "source": [
    "weights_path = 'C:/Users/AS-GP/Desktop/MobileNet/MNV2_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RkDxR-VC654"
   },
   "outputs": [],
   "source": [
    "#Later to restore:\n",
    "model.load_state_dict(torch.load(weights_path))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
